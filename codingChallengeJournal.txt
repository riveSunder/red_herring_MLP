# Email states that coding channel requires python 3 and tensorflow 1.4 (latest tensorflow is now 1.9, according to their Github)
# Try to create a conda environment specific to the coding channel, get error:Fetching package metadata ...........
conda create -n openAI python=3.7 tensorflow=1.4

#Solving package specifications: .
#UnsatisfiableError: The following specifications were found to be in conflict:
#  - python 3.7*
#  - tensorflow 1.4* -> tensorflow-base 1.4.1 -> enum34 >=1.1.6 -> python 2.7* -> openssl 1.0.1*
#  - tensorflow 1.4* -> tensorflow-base 1.4.1 -> enum34 >=1.1.6 -> python 2.7* -> readline 6.2*
#  - tensorflow 1.4* -> tensorflow-base 1.4.1 -> enum34 >=1.1.6 -> python 2.7* -> tk 8.5*
#Use "conda info <package>" to see the dependencies for each package.

# The same command with python=3.6 completes with no problems. I guess python=3.7.0 (released 2018-06-28) is too new for conda. 

# Before I tried python=3.6, also made a virtual-env for the coding challenge.


sudo apt-get install python3-pip python3-dev python-virtualenv
virtualenv --system-site-packages -p python3 ./tensorflowVE/
source ./tensorflow/bin/activate
pip3 install --upgrade tensorflow==1.4


# I wrote a 7 layer fully connected classifier with flags for various hyperparameters and for specifying a logdir for tensorboard
# Three datasets are available (also specified via flags): iris, wine quality, and digits, all from scikit-learn datasets

# Added summary ops for tensorboard visualizations. 
# I've gather that the merge_all op should follow all of the summary ops in the graph definition. It won't do to define the merge op in the training loop or else it will write new events for each iteration (appended with _number).
# However the summary writer op is called in the training loop.

# With how I've built it so far, I can't log both training and validation accuracy/loss, because the summary ops are defined (and named) in the graph and the summary writer is called from the training loop. Therefore, everything that is logged is from validation runs. 


# Using the tf.layers and tf.contrib.learn, I wrote another, more abstraced MLP model for classification. This one has better performance than the low-level model using tf.matmul operations. 
